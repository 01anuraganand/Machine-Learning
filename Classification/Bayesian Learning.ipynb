{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a87762fd-2b89-40ea-97e9-947aeb78978d",
   "metadata": {},
   "source": [
    "# Bayesian Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b50fa8b-52a4-44df-8a8e-2c3f88ad0d87",
   "metadata": {},
   "source": [
    "Bayesian reasoning provides a probabilistic approach to \n",
    "inference.It is based on the assumption that the quantities of interest \n",
    "are governed by probability distributions and that optimal \n",
    "decisions can be made by reasoning about these \n",
    "probabilities together with observed data.\n",
    "\n",
    "Bayesian learning methods are relevant to our study of \n",
    "machine learning for two different reasons.\n",
    " - Bayesian learning algorithms that calculate explicit probabilities \n",
    "for hypotheses, such as the naive Bayes classifier, are among the \n",
    "most practical approaches to certain types of learning problems.\n",
    " - They provide a useful perspective for understanding many \n",
    "learning algorithms that do not explicitly manipulate \n",
    "probabilities\n",
    "\n",
    "## Features of Bayesian learning methods\n",
    "\n",
    " -  Each observed training example can incrementally\n",
    "decrease or increase the estimated probability that a\n",
    "hypothesis is correct.\n",
    " - Prior knowledge can be combined with observed data\n",
    "to determine the final probability of a hypothesis.\n",
    " - Bayesian methods can accommodate hypotheses that\n",
    "make probabilistic predictions\n",
    " - New instances can be classified by combining the\n",
    "predictions of multiple hypotheses, weighted by their\n",
    "probabilities.\n",
    " - Even in cases where Bayesian methods prove\n",
    "computationally intractable, they can provide a\n",
    "standard of optimal decision making against which\n",
    "other practical methods can be measured.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "212081d0-adbe-4614-b09e-8ad42964e0cc",
   "metadata": {},
   "source": [
    "# Bayes Theorem\n",
    "If $E_1, E_2, ... , E_n $ are n mutually disjoint event with $P(E_i) \\neq 0, ~ \\forall i$ then for any event $A$ which is a subset of $E_i$ such that $P(A) > 0$ then:\n",
    "\n",
    "$\\large P(E_i|A) = \\frac{P(E_i)P(A|E_i)}{\\sum_{i = 1}^{n}P(E_i)P(A|E_i)} \\Rightarrow \\frac{P(E_i)P(A|E_i)}{P(A)}$\n",
    "\n",
    "$P(A) = {\\sum_{i = 1}^{n}P(E_i)P(A|E_i)} $ refers to theorem of total probability\n",
    "\n",
    "A <b>prior probability</b> is an initial probability value originally \n",
    "obtained before any additional information is obtained.\n",
    "\n",
    "A <b>posterior probability</b> is a probability value that has been \n",
    "revised by using additional information that is later obtained.\n",
    "\n",
    "\n",
    "we also demonstrate Bayes theorem as in term of hypothesis:\n",
    "\n",
    "$\\large P(h|D) = \\frac{P(D|h)P(h)}{P(D)}$\n",
    "\n",
    " - $P(h)$ - prior probability of hypothesis h\n",
    " - $P(D)$ - prior probability of training data D\n",
    " - $P(h|D)$ - probability of h given D\n",
    " - $P(D|h)$ - probability of D given h"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1431de6-cf60-4891-952c-50c4db43efe7",
   "metadata": {},
   "source": [
    "# Choosing Hypothesis\n",
    "Generally we want the most probable hypothesis given the training data.\n",
    "\n",
    "<b>Maximum a posteriori hypothesis</b> $h_{MAP}$\n",
    "\n",
    "$$\\large h_{MAP} = \\underset{h \\in H}{arg max} ~ P(h|D) $$\n",
    "$$\\large \\qquad \\quad\\Rightarrow \\underset{h \\in H}{arg max} ~\\frac{P(D|h)P(h)}{P(D)}$$\n",
    "$$\\large \\qquad \\quad\\Rightarrow \\underset{h \\in H}{arg max}~ {P(D|h)P(h)}$$\n",
    "\n",
    "If we assume $P(h_i) = P(h_j)$ then can further simplify and choose the <b>Maximum Likelihood(ML)  </b>hypothesis\n",
    "\n",
    "$$\\large h_{ML} = \\underset{h_i \\in H}{arg max}~ P(D|h_i)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f510a80-071d-4231-9eb9-8c79c8cd60bc",
   "metadata": {},
   "source": [
    "# Brute Force MAP  Learning Algorithm\n",
    " 1. For each hypothesis h in H , calculate posterior probability $\\large P(h|D) = \\frac{P(D|h)P(h)}{P(D)}$\n",
    " 2. Output the hypothesis $\\large h_{MAP} = \\underset{h \\in H}{arg max} P(h|D)$\n",
    " \n",
    "Lets consider following assumptions\n",
    "1. The training data D is noise free $(i.e., d_i = c(x_i))$.\n",
    "2. The target concept c is contained in the hypothesis space H\n",
    "3. We have no a priori reason to believe that any hypothesis is more probable than any other.\n",
    "what values should we specify for P(h)?\n",
    "\n",
    "$P(h) = \\frac{1}{|H|}$ for all h in H\n",
    "\n",
    "What choice shall we make for $P(D|h)$?\n",
    "\n",
    "$P(D|h)$ is the probability of observing the target values $D = <d_1 . . .d_m> $ for the fixed set of instances $<X_1 . . . X_m>$, given a world in which hypothesis h holds\n",
    "\n",
    "\n",
    "$$\n",
    "\\large P(D|h) = \n",
    "\\begin{cases}\n",
    "\\text{1 $\\qquad$ if $d_i = h(x_i)$ for all $d_i$ in D }\\\\\n",
    "\\text{0 $\\qquad$ Ohterwise}\n",
    "\\end{cases}\\\\\n",
    "$$\n",
    "\n",
    "In other words, the probablility of data D given hypothesis h is 1 if D is consistent with h and 0 otherwise.\n",
    "$$P(h|D) = \\frac{0.P(h)}{P(D)} \\Rightarrow 0 \\quad $$ if h is inconsistent with D\n",
    "\n",
    "The posterior probability of a hypothesis inconsistent with D is zero. \n",
    "\n",
    "Now consider the case where h is consistent with D\n",
    "\n",
    "$$\n",
    "P(h|D) = \\frac{1\\frac{1}{|H|}}{P(D)}\n",
    "$$\n",
    "$\\therefore P(D) = \\underset{h_i \\in H}\\sum{P(D|h_i)P(h_i)}$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e9ddad3-0a2f-484e-9ba7-dfa977a9b871",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d83e4864-846e-4fea-80e4-5d34647671e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6204cc7-eda5-45f7-940d-edef5860e0e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09f3fbd7-0b0f-4d2d-b35e-420d91c5bd95",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f89dc9d-33d7-4e8b-9215-dcb2e7910bc4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0728c1e1-8f54-4c8f-866b-0eb7166f3cb4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abceca8b-2771-4efb-84ad-0b930440c8be",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
